Model(
  (feature_extractor): InceptionTimePlus(
    (backbone): Sequential(
      (0): InceptionBlockPlus(
        (inception): ModuleList(
          (0): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (1): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (2): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (4): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (5): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (shortcut): ModuleList(
          (0): ConvBlock(
            (0): Conv1d(10, 128, kernel_size=(1,), stride=(1,), bias=False)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): ModuleList(
          (0): ReLU()
          (1): ReLU()
        )
        (add): Add
      )
    )
    (head): Sequential(
      (0): Sequential(
        (0): GAP1d(
          (gap): AdaptiveAvgPool1d(output_size=1)
          (flatten): Reshape(bs)
        )
        (1): LinBnDrop(
          (0): Linear(in_features=128, out_features=5, bias=True)
        )
      )
    )
  )
  (fc): Linear(in_features=5, out_features=5, bias=True)
)
number of parameters: 457251
Training start
epoch  1 | time used:  2.83s | train_loss 1.596 | valid loss 1.441 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  2 | time used:  1.56s | train_loss 1.601 | valid loss 1.443 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  3 | time used:  1.58s | train_loss 1.606 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  4 | time used:  1.61s | train_loss 1.609 | valid loss 1.444 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  5 | time used:  1.58s | train_loss 1.593 | valid loss 1.441 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  6 | time used:  1.61s | train_loss 1.595 | valid loss 1.439 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  7 | time used:  1.52s | train_loss 1.573 | valid loss 1.540 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  8 | time used:  1.48s | train_loss 1.591 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  9 | time used:  1.49s | train_loss 1.602 | valid loss 1.502 | valid acc 0.393 | mae 2.085 | mse 7.747 | rmse 2.78 | r2 -1.30
epoch 10 | time used:  1.49s | train_loss 1.567 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
saving the model to ./save/preTCN/2020_300/checkpoint10.pt
epoch 11 | time used:  1.47s | train_loss 1.573 | valid loss 1.821 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 12 | time used:  1.48s | train_loss 1.562 | valid loss 1.810 | valid acc 0.045 | mae 1.925 | mse 4.793 | rmse 2.19 | r2 -0.42
epoch 13 | time used:  1.45s | train_loss 1.588 | valid loss 1.443 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 14 | time used:  1.44s | train_loss 1.578 | valid loss 1.533 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 15 | time used:  1.42s | train_loss 1.572 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 16 | time used:  1.47s | train_loss 1.605 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 17 | time used:  1.50s | train_loss 1.635 | valid loss 1.593 | valid acc 0.045 | mae 1.925 | mse 4.793 | rmse 2.19 | r2 -0.42
epoch 18 | time used:  1.60s | train_loss 1.677 | valid loss 1.541 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 19 | time used:  1.61s | train_loss 1.618 | valid loss 1.823 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 20 | time used:  1.57s | train_loss 1.635 | valid loss 1.820 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
saving the model to ./save/preTCN/2020_300/checkpoint20.pt