Model(
  (feature_extractor): InceptionTimePlus(
    (backbone): Sequential(
      (0): InceptionBlockPlus(
        (inception): ModuleList(
          (0): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (1): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (2): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (4): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (5): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (shortcut): ModuleList(
          (0): ConvBlock(
            (0): Conv1d(10, 128, kernel_size=(1,), stride=(1,), bias=False)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): ModuleList(
          (0): ReLU()
          (1): ReLU()
        )
        (add): Add
      )
    )
    (head): Sequential(
      (0): Sequential(
        (0): GAP1d(
          (gap): AdaptiveAvgPool1d(output_size=1)
          (flatten): Reshape(bs)
        )
        (1): LinBnDrop(
          (0): Linear(in_features=128, out_features=5, bias=True)
        )
      )
    )
  )
  (fc): Linear(in_features=5, out_features=5, bias=True)
)
number of parameters: 457251
Training start
epoch  1 | time used:  2.75s | train_loss 1.590 | valid loss 1.530 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  2 | time used:  1.46s | train_loss 1.576 | valid loss 1.541 | valid acc 0.363 | mae 2.190 | mse 8.148 | rmse 2.85 | r2 -1.42
epoch  3 | time used:  1.63s | train_loss 1.567 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  4 | time used:  1.73s | train_loss 1.572 | valid loss 1.537 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  5 | time used:  1.78s | train_loss 1.624 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  6 | time used:  1.56s | train_loss 1.626 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  7 | time used:  1.46s | train_loss 1.594 | valid loss 1.439 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  8 | time used:  1.48s | train_loss 1.599 | valid loss 1.540 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  9 | time used:  1.49s | train_loss 1.617 | valid loss 1.445 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 10 | time used:  1.48s | train_loss 1.581 | valid loss 1.465 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
saving the model to ./save/preTCN/2020_300/checkpoint10.pt
epoch 11 | time used:  1.50s | train_loss 1.576 | valid loss 1.821 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 12 | time used:  1.47s | train_loss 1.656 | valid loss 1.537 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 13 | time used:  1.41s | train_loss 1.621 | valid loss 1.823 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 14 | time used:  1.49s | train_loss 1.645 | valid loss 1.823 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 15 | time used:  1.50s | train_loss 1.627 | valid loss 1.451 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 16 | time used:  1.47s | train_loss 1.611 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 17 | time used:  1.48s | train_loss 1.626 | valid loss 1.441 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 18 | time used:  1.47s | train_loss 1.610 | valid loss 1.541 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 19 | time used:  1.42s | train_loss 1.576 | valid loss 1.737 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 20 | time used:  1.42s | train_loss 1.626 | valid loss 1.820 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
saving the model to ./save/preTCN/2020_300/checkpoint20.pt