Model(
  (feature_extractor): InceptionTimePlus(
    (backbone): Sequential(
      (0): InceptionBlockPlus(
        (inception): ModuleList(
          (0): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(10, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (1): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (2): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (3): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (4): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (act): ReLU()
          )
          (5): InceptionModulePlus(
            (bottleneck): ConvBlock(
              (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            )
            (convs): ModuleList(
              (0): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,), bias=False)
              )
              (1): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,), bias=False)
              )
              (2): ConvBlock(
                (0): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,), bias=False)
              )
            )
            (mp_conv): Sequential(
              (0): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)
              (1): ConvBlock(
                (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
              )
            )
            (concat): Concat(dim=1)
            (norm): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (shortcut): ModuleList(
          (0): ConvBlock(
            (0): Conv1d(10, 128, kernel_size=(1,), stride=(1,), bias=False)
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (act): ModuleList(
          (0): ReLU()
          (1): ReLU()
        )
        (add): Add
      )
    )
    (head): Sequential(
      (0): Sequential(
        (0): GAP1d(
          (gap): AdaptiveAvgPool1d(output_size=1)
          (flatten): Reshape(bs)
        )
        (1): LinBnDrop(
          (0): Linear(in_features=128, out_features=5, bias=True)
        )
      )
    )
  )
  (fc): Linear(in_features=5, out_features=5, bias=True)
)
number of parameters: 457251
Training start
epoch  1 | time used:  2.72s | train_loss 1.590 | valid loss 1.540 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  2 | time used:  1.79s | train_loss 1.573 | valid loss 1.538 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  3 | time used:  1.80s | train_loss 1.603 | valid loss 1.859 | valid acc 0.045 | mae 1.925 | mse 4.793 | rmse 2.19 | r2 -0.42
epoch  4 | time used:  1.71s | train_loss 1.613 | valid loss 1.444 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  5 | time used:  1.57s | train_loss 1.611 | valid loss 1.441 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  6 | time used:  1.75s | train_loss 1.623 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  7 | time used:  1.77s | train_loss 1.707 | valid loss 1.540 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch  8 | time used:  1.78s | train_loss 1.605 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch  9 | time used:  1.58s | train_loss 1.611 | valid loss 1.537 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 10 | time used:  1.47s | train_loss 1.622 | valid loss 1.538 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
saving the model to ./save/preTCN/2020_300/checkpoint10.pt
epoch 11 | time used:  1.36s | train_loss 1.625 | valid loss 1.538 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 12 | time used:  1.37s | train_loss 1.631 | valid loss 1.823 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 13 | time used:  1.43s | train_loss 1.647 | valid loss 1.823 | valid acc 0.083 | mae 1.747 | mse 3.407 | rmse 1.85 | r2 -0.01
epoch 14 | time used:  1.46s | train_loss 1.639 | valid loss 1.537 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 15 | time used:  1.49s | train_loss 1.563 | valid loss 1.513 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 16 | time used:  1.49s | train_loss 1.562 | valid loss 1.440 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 17 | time used:  1.45s | train_loss 1.589 | valid loss 1.540 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
epoch 18 | time used:  1.42s | train_loss 1.561 | valid loss 1.425 | valid acc 0.464 | mae 1.807 | mse 6.635 | rmse 2.58 | r2 -0.97
epoch 19 | time used:  1.43s | train_loss 1.569 | valid loss 1.711 | valid acc 0.046 | mae 1.907 | mse 4.693 | rmse 2.17 | r2 -0.39
epoch 20 | time used:  1.45s | train_loss 1.661 | valid loss 1.539 | valid acc 0.366 | mae 2.193 | mse 8.179 | rmse 2.86 | r2 -1.43
saving the model to ./save/preTCN/2020_300/checkpoint20.pt